{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe6e21d",
   "metadata": {},
   "source": [
    "# *Import Packages and Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9bb594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-datareader in c:\\users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages (from pandas-datareader) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages (from pandas-datareader) (2.31.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages (from pandas-datareader) (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2024.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prave\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.19.0->pandas-datareader) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.23->pandas-datareader) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing the \"pandas datareader\" package\n",
    "!pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8970aad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\prave\\anaconda3\\envs\\tensorflow3.9.5\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Imported various Python libraries for working with data, financial data retrieval, visualization, and machine learning.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader as pdr\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "\n",
    "# For time stamps\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70779f0",
   "metadata": {},
   "source": [
    "# *Extracting Data from yfinance*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abefcc84",
   "metadata": {},
   "source": [
    "### *Assigning Start and End date to variables for extracting data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1abb5630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Assign the date '01/04/2018' to the variable 'start' with datetime format\n",
    "start = datetime.strptime('01/03/2018 00:00:00', '%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "# Display the value of 'start'\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4565ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Assign the date '01/04/2023' to the variable 'end' with datetime format\n",
    "end = datetime.strptime('01/03/2024 00:00:00', '%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "# Display the value of 'end'\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708fbf6",
   "metadata": {},
   "source": [
    "## *Company: HCL Technologies Ltd.*\n",
    "## *Industry: Information Technology Consulting Outsourcing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d137e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>471.899994</td>\n",
       "      <td>476.225006</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>471.399994</td>\n",
       "      <td>403.986603</td>\n",
       "      <td>2772230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>471.399994</td>\n",
       "      <td>472.325012</td>\n",
       "      <td>458.899994</td>\n",
       "      <td>466.049988</td>\n",
       "      <td>399.401703</td>\n",
       "      <td>3747704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>469.000000</td>\n",
       "      <td>476.500000</td>\n",
       "      <td>463.250000</td>\n",
       "      <td>466.399994</td>\n",
       "      <td>399.701508</td>\n",
       "      <td>2929756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-07</th>\n",
       "      <td>469.000000</td>\n",
       "      <td>476.399994</td>\n",
       "      <td>466.899994</td>\n",
       "      <td>474.774994</td>\n",
       "      <td>406.878906</td>\n",
       "      <td>5695220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-08</th>\n",
       "      <td>476.500000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>472.774994</td>\n",
       "      <td>475.325012</td>\n",
       "      <td>407.350250</td>\n",
       "      <td>4238350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-23</th>\n",
       "      <td>1697.000000</td>\n",
       "      <td>1697.349976</td>\n",
       "      <td>1663.449951</td>\n",
       "      <td>1665.750000</td>\n",
       "      <td>1665.750000</td>\n",
       "      <td>2191549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-26</th>\n",
       "      <td>1665.750000</td>\n",
       "      <td>1668.849976</td>\n",
       "      <td>1639.500000</td>\n",
       "      <td>1649.800049</td>\n",
       "      <td>1649.800049</td>\n",
       "      <td>1844253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-27</th>\n",
       "      <td>1649.000000</td>\n",
       "      <td>1673.400024</td>\n",
       "      <td>1648.000000</td>\n",
       "      <td>1658.800049</td>\n",
       "      <td>1658.800049</td>\n",
       "      <td>2049420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-28</th>\n",
       "      <td>1664.699951</td>\n",
       "      <td>1672.000000</td>\n",
       "      <td>1644.199951</td>\n",
       "      <td>1651.900024</td>\n",
       "      <td>1651.900024</td>\n",
       "      <td>936575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29</th>\n",
       "      <td>1642.150024</td>\n",
       "      <td>1677.750000</td>\n",
       "      <td>1636.650024</td>\n",
       "      <td>1663.849976</td>\n",
       "      <td>1663.849976</td>\n",
       "      <td>3532888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1482 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2018-03-01   471.899994   476.225006   469.000000   471.399994   403.986603   \n",
       "2018-03-05   471.399994   472.325012   458.899994   466.049988   399.401703   \n",
       "2018-03-06   469.000000   476.500000   463.250000   466.399994   399.701508   \n",
       "2018-03-07   469.000000   476.399994   466.899994   474.774994   406.878906   \n",
       "2018-03-08   476.500000   482.000000   472.774994   475.325012   407.350250   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2024-02-23  1697.000000  1697.349976  1663.449951  1665.750000  1665.750000   \n",
       "2024-02-26  1665.750000  1668.849976  1639.500000  1649.800049  1649.800049   \n",
       "2024-02-27  1649.000000  1673.400024  1648.000000  1658.800049  1658.800049   \n",
       "2024-02-28  1664.699951  1672.000000  1644.199951  1651.900024  1651.900024   \n",
       "2024-02-29  1642.150024  1677.750000  1636.650024  1663.849976  1663.849976   \n",
       "\n",
       "             Volume  \n",
       "Date                 \n",
       "2018-03-01  2772230  \n",
       "2018-03-05  3747704  \n",
       "2018-03-06  2929756  \n",
       "2018-03-07  5695220  \n",
       "2018-03-08  4238350  \n",
       "...             ...  \n",
       "2024-02-23  2191549  \n",
       "2024-02-26  1844253  \n",
       "2024-02-27  2049420  \n",
       "2024-02-28   936575  \n",
       "2024-02-29  3532888  \n",
       "\n",
       "[1482 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hcltech = yf.download(\"HCLTECH.NS\", start, end)\n",
    "hcltech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d3e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting csv for reference\n",
    "#hcltech.to_csv(\"hcltech_file.csv\", index = True)\n",
    "\n",
    "# Importing DataFrame\n",
    "#hcltech = pd.read_csv('/kaggle/input/hcltech/hcltech_file.csv')\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "#hcltech.set_index('Date', inplace=True)\n",
    "\n",
    "# Printing the DataFrame\n",
    "#print(hcltech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc27f4",
   "metadata": {},
   "source": [
    "## *Company: Sun Pharmaceutical Industries Ltd.*\n",
    "## *Industry: Pharmaceutical*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827ece0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>537.950012</td>\n",
       "      <td>541.500000</td>\n",
       "      <td>533.250000</td>\n",
       "      <td>535.400024</td>\n",
       "      <td>505.355682</td>\n",
       "      <td>4264631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>535.099976</td>\n",
       "      <td>552.700012</td>\n",
       "      <td>527.049988</td>\n",
       "      <td>548.549988</td>\n",
       "      <td>517.767822</td>\n",
       "      <td>7343286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>561.000000</td>\n",
       "      <td>563.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>531.750000</td>\n",
       "      <td>501.910553</td>\n",
       "      <td>9825945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-07</th>\n",
       "      <td>532.000000</td>\n",
       "      <td>534.150024</td>\n",
       "      <td>520.099976</td>\n",
       "      <td>524.849976</td>\n",
       "      <td>495.397675</td>\n",
       "      <td>6282066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-08</th>\n",
       "      <td>529.700012</td>\n",
       "      <td>530.500000</td>\n",
       "      <td>509.500000</td>\n",
       "      <td>514.599976</td>\n",
       "      <td>485.722931</td>\n",
       "      <td>9316674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-23</th>\n",
       "      <td>1558.000000</td>\n",
       "      <td>1568.449951</td>\n",
       "      <td>1550.400024</td>\n",
       "      <td>1561.250000</td>\n",
       "      <td>1561.250000</td>\n",
       "      <td>1340283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-26</th>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1566.900024</td>\n",
       "      <td>1548.699951</td>\n",
       "      <td>1556.949951</td>\n",
       "      <td>1556.949951</td>\n",
       "      <td>974892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-27</th>\n",
       "      <td>1556.750000</td>\n",
       "      <td>1585.449951</td>\n",
       "      <td>1549.050049</td>\n",
       "      <td>1582.750000</td>\n",
       "      <td>1582.750000</td>\n",
       "      <td>2140963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-28</th>\n",
       "      <td>1586.500000</td>\n",
       "      <td>1587.449951</td>\n",
       "      <td>1562.650024</td>\n",
       "      <td>1573.849976</td>\n",
       "      <td>1573.849976</td>\n",
       "      <td>578316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29</th>\n",
       "      <td>1575.000000</td>\n",
       "      <td>1587.800049</td>\n",
       "      <td>1556.500000</td>\n",
       "      <td>1577.949951</td>\n",
       "      <td>1577.949951</td>\n",
       "      <td>2350244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1482 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2018-03-01   537.950012   541.500000   533.250000   535.400024   505.355682   \n",
       "2018-03-05   535.099976   552.700012   527.049988   548.549988   517.767822   \n",
       "2018-03-06   561.000000   563.000000   530.000000   531.750000   501.910553   \n",
       "2018-03-07   532.000000   534.150024   520.099976   524.849976   495.397675   \n",
       "2018-03-08   529.700012   530.500000   509.500000   514.599976   485.722931   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2024-02-23  1558.000000  1568.449951  1550.400024  1561.250000  1561.250000   \n",
       "2024-02-26  1562.000000  1566.900024  1548.699951  1556.949951  1556.949951   \n",
       "2024-02-27  1556.750000  1585.449951  1549.050049  1582.750000  1582.750000   \n",
       "2024-02-28  1586.500000  1587.449951  1562.650024  1573.849976  1573.849976   \n",
       "2024-02-29  1575.000000  1587.800049  1556.500000  1577.949951  1577.949951   \n",
       "\n",
       "             Volume  \n",
       "Date                 \n",
       "2018-03-01  4264631  \n",
       "2018-03-05  7343286  \n",
       "2018-03-06  9825945  \n",
       "2018-03-07  6282066  \n",
       "2018-03-08  9316674  \n",
       "...             ...  \n",
       "2024-02-23  1340283  \n",
       "2024-02-26   974892  \n",
       "2024-02-27  2140963  \n",
       "2024-02-28   578316  \n",
       "2024-02-29  2350244  \n",
       "\n",
       "[1482 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunpharma = yf.download(\"SUNPHARMA.NS\", start, end)\n",
    "sunpharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34212916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting csv for reference\n",
    "#sunpharma.to_csv(\"sunpharma_file.csv\", index = True)\n",
    "\n",
    "# Importing DataFrame\n",
    "#sunpharma = pd.read_csv('/kaggle/input/sunpharma/sunpharma_file.csv')\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "#sunpharma.set_index('Date', inplace=True)\n",
    "\n",
    "# Printing the DataFrame\n",
    "#print(sunpharma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d939e33",
   "metadata": {},
   "source": [
    "## *Company: HDFC Bank Ltd.*\n",
    "## *Industry: Financial Services*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00a9cebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>939.650024</td>\n",
       "      <td>946.650024</td>\n",
       "      <td>934.000000</td>\n",
       "      <td>937.174988</td>\n",
       "      <td>898.568359</td>\n",
       "      <td>1954920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>937.075012</td>\n",
       "      <td>939.000000</td>\n",
       "      <td>929.125000</td>\n",
       "      <td>934.974976</td>\n",
       "      <td>896.458923</td>\n",
       "      <td>1890732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>935.000000</td>\n",
       "      <td>939.950012</td>\n",
       "      <td>919.750000</td>\n",
       "      <td>923.125000</td>\n",
       "      <td>885.097168</td>\n",
       "      <td>2288414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-07</th>\n",
       "      <td>920.000000</td>\n",
       "      <td>926.700012</td>\n",
       "      <td>914.250000</td>\n",
       "      <td>916.299988</td>\n",
       "      <td>878.553284</td>\n",
       "      <td>2814082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-08</th>\n",
       "      <td>919.900024</td>\n",
       "      <td>929.250000</td>\n",
       "      <td>916.000000</td>\n",
       "      <td>926.424988</td>\n",
       "      <td>888.261230</td>\n",
       "      <td>2759362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-23</th>\n",
       "      <td>1422.550049</td>\n",
       "      <td>1433.900024</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>1420.599976</td>\n",
       "      <td>1420.599976</td>\n",
       "      <td>14916726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-26</th>\n",
       "      <td>1413.550049</td>\n",
       "      <td>1434.849976</td>\n",
       "      <td>1413.550049</td>\n",
       "      <td>1422.300049</td>\n",
       "      <td>1422.300049</td>\n",
       "      <td>11753435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-27</th>\n",
       "      <td>1413.550049</td>\n",
       "      <td>1426.699951</td>\n",
       "      <td>1413.050049</td>\n",
       "      <td>1420.150024</td>\n",
       "      <td>1420.150024</td>\n",
       "      <td>16043575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-28</th>\n",
       "      <td>1420.150024</td>\n",
       "      <td>1424.199951</td>\n",
       "      <td>1404.000000</td>\n",
       "      <td>1409.400024</td>\n",
       "      <td>1409.400024</td>\n",
       "      <td>12660993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29</th>\n",
       "      <td>1402.099976</td>\n",
       "      <td>1410.400024</td>\n",
       "      <td>1397.300049</td>\n",
       "      <td>1403.400024</td>\n",
       "      <td>1403.400024</td>\n",
       "      <td>26647850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1482 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2018-03-01   939.650024   946.650024   934.000000   937.174988   898.568359   \n",
       "2018-03-05   937.075012   939.000000   929.125000   934.974976   896.458923   \n",
       "2018-03-06   935.000000   939.950012   919.750000   923.125000   885.097168   \n",
       "2018-03-07   920.000000   926.700012   914.250000   916.299988   878.553284   \n",
       "2018-03-08   919.900024   929.250000   916.000000   926.424988   888.261230   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2024-02-23  1422.550049  1433.900024  1418.000000  1420.599976  1420.599976   \n",
       "2024-02-26  1413.550049  1434.849976  1413.550049  1422.300049  1422.300049   \n",
       "2024-02-27  1413.550049  1426.699951  1413.050049  1420.150024  1420.150024   \n",
       "2024-02-28  1420.150024  1424.199951  1404.000000  1409.400024  1409.400024   \n",
       "2024-02-29  1402.099976  1410.400024  1397.300049  1403.400024  1403.400024   \n",
       "\n",
       "              Volume  \n",
       "Date                  \n",
       "2018-03-01   1954920  \n",
       "2018-03-05   1890732  \n",
       "2018-03-06   2288414  \n",
       "2018-03-07   2814082  \n",
       "2018-03-08   2759362  \n",
       "...              ...  \n",
       "2024-02-23  14916726  \n",
       "2024-02-26  11753435  \n",
       "2024-02-27  16043575  \n",
       "2024-02-28  12660993  \n",
       "2024-02-29  26647850  \n",
       "\n",
       "[1482 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdfcbank = yf.download(\"HDFCBANK.NS\", start, end)\n",
    "hdfcbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "724a5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting csv for reference\n",
    "#hdfcbank.to_csv(\"hdfcbank_file.csv\", index = True)\n",
    "\n",
    "# Importing DataFrame\n",
    "#hdfcbank = pd.read_csv('/kaggle/input/hdfcbank/hdfcbank_file.csv')\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "#hdfcbank.set_index('Date', inplace=True)\n",
    "\n",
    "# Printing the DataFrame\n",
    "#print(hdfcbank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deace71",
   "metadata": {},
   "source": [
    "## *Company: DLF Ltd.*\n",
    "## *Industry: Real Estate Development*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e90687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>225.550003</td>\n",
       "      <td>228.250000</td>\n",
       "      <td>223.149994</td>\n",
       "      <td>224.300003</td>\n",
       "      <td>212.629013</td>\n",
       "      <td>3581145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>221.300003</td>\n",
       "      <td>223.949997</td>\n",
       "      <td>219.699997</td>\n",
       "      <td>222.899994</td>\n",
       "      <td>211.301834</td>\n",
       "      <td>3539064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>224.399994</td>\n",
       "      <td>226.649994</td>\n",
       "      <td>214.050003</td>\n",
       "      <td>216.550003</td>\n",
       "      <td>205.282272</td>\n",
       "      <td>6144090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-07</th>\n",
       "      <td>215.000000</td>\n",
       "      <td>217.750000</td>\n",
       "      <td>212.199997</td>\n",
       "      <td>215.449997</td>\n",
       "      <td>204.239502</td>\n",
       "      <td>5878878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-08</th>\n",
       "      <td>216.550003</td>\n",
       "      <td>219.649994</td>\n",
       "      <td>209.750000</td>\n",
       "      <td>218.399994</td>\n",
       "      <td>207.035995</td>\n",
       "      <td>6237904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-23</th>\n",
       "      <td>898.000000</td>\n",
       "      <td>905.000000</td>\n",
       "      <td>892.349976</td>\n",
       "      <td>899.250000</td>\n",
       "      <td>899.250000</td>\n",
       "      <td>3438995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-26</th>\n",
       "      <td>898.000000</td>\n",
       "      <td>910.250000</td>\n",
       "      <td>887.700012</td>\n",
       "      <td>902.900024</td>\n",
       "      <td>902.900024</td>\n",
       "      <td>4080998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-27</th>\n",
       "      <td>905.000000</td>\n",
       "      <td>918.200012</td>\n",
       "      <td>902.900024</td>\n",
       "      <td>916.400024</td>\n",
       "      <td>916.400024</td>\n",
       "      <td>3614155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-28</th>\n",
       "      <td>914.200012</td>\n",
       "      <td>919.950012</td>\n",
       "      <td>893.599976</td>\n",
       "      <td>899.000000</td>\n",
       "      <td>899.000000</td>\n",
       "      <td>3541248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29</th>\n",
       "      <td>898.000000</td>\n",
       "      <td>911.950012</td>\n",
       "      <td>881.650024</td>\n",
       "      <td>901.200012</td>\n",
       "      <td>901.200012</td>\n",
       "      <td>19571487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1482 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2018-03-01  225.550003  228.250000  223.149994  224.300003  212.629013   \n",
       "2018-03-05  221.300003  223.949997  219.699997  222.899994  211.301834   \n",
       "2018-03-06  224.399994  226.649994  214.050003  216.550003  205.282272   \n",
       "2018-03-07  215.000000  217.750000  212.199997  215.449997  204.239502   \n",
       "2018-03-08  216.550003  219.649994  209.750000  218.399994  207.035995   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2024-02-23  898.000000  905.000000  892.349976  899.250000  899.250000   \n",
       "2024-02-26  898.000000  910.250000  887.700012  902.900024  902.900024   \n",
       "2024-02-27  905.000000  918.200012  902.900024  916.400024  916.400024   \n",
       "2024-02-28  914.200012  919.950012  893.599976  899.000000  899.000000   \n",
       "2024-02-29  898.000000  911.950012  881.650024  901.200012  901.200012   \n",
       "\n",
       "              Volume  \n",
       "Date                  \n",
       "2018-03-01   3581145  \n",
       "2018-03-05   3539064  \n",
       "2018-03-06   6144090  \n",
       "2018-03-07   5878878  \n",
       "2018-03-08   6237904  \n",
       "...              ...  \n",
       "2024-02-23   3438995  \n",
       "2024-02-26   4080998  \n",
       "2024-02-27   3614155  \n",
       "2024-02-28   3541248  \n",
       "2024-02-29  19571487  \n",
       "\n",
       "[1482 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlf = yf.download(\"DLF.NS\", start, end)\n",
    "dlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "544f1e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting csv for reference\n",
    "#dlf.to_csv(\"dlf_file.csv\", index = True)\n",
    "\n",
    "\n",
    "# Importing DataFrame\n",
    "#dlf = pd.read_csv('/kaggle/input/dlf-df/dlf_file.csv')\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "#dlf.set_index('Date', inplace=True)\n",
    "\n",
    "# Printing the DataFrame\n",
    "#print(dlf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e474e",
   "metadata": {},
   "source": [
    "## *Index: NIFTY50*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46de67d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>10479.950195</td>\n",
       "      <td>10525.500000</td>\n",
       "      <td>10447.150391</td>\n",
       "      <td>10458.349609</td>\n",
       "      <td>10458.349609</td>\n",
       "      <td>176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>10428.299805</td>\n",
       "      <td>10428.700195</td>\n",
       "      <td>10323.900391</td>\n",
       "      <td>10358.849609</td>\n",
       "      <td>10358.849609</td>\n",
       "      <td>194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>10420.500000</td>\n",
       "      <td>10441.349609</td>\n",
       "      <td>10215.900391</td>\n",
       "      <td>10249.250000</td>\n",
       "      <td>10249.250000</td>\n",
       "      <td>222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-07</th>\n",
       "      <td>10232.950195</td>\n",
       "      <td>10243.349609</td>\n",
       "      <td>10141.549805</td>\n",
       "      <td>10154.200195</td>\n",
       "      <td>10154.200195</td>\n",
       "      <td>249500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-08</th>\n",
       "      <td>10216.250000</td>\n",
       "      <td>10270.349609</td>\n",
       "      <td>10146.400391</td>\n",
       "      <td>10242.650391</td>\n",
       "      <td>10242.650391</td>\n",
       "      <td>226400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-23</th>\n",
       "      <td>22290.000000</td>\n",
       "      <td>22297.500000</td>\n",
       "      <td>22186.099609</td>\n",
       "      <td>22212.699219</td>\n",
       "      <td>22212.699219</td>\n",
       "      <td>226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-26</th>\n",
       "      <td>22169.199219</td>\n",
       "      <td>22202.150391</td>\n",
       "      <td>22075.150391</td>\n",
       "      <td>22122.050781</td>\n",
       "      <td>22122.050781</td>\n",
       "      <td>207800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-27</th>\n",
       "      <td>22090.199219</td>\n",
       "      <td>22218.250000</td>\n",
       "      <td>22085.650391</td>\n",
       "      <td>22198.349609</td>\n",
       "      <td>22198.349609</td>\n",
       "      <td>252200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-28</th>\n",
       "      <td>22214.099609</td>\n",
       "      <td>22229.150391</td>\n",
       "      <td>21915.849609</td>\n",
       "      <td>21951.150391</td>\n",
       "      <td>21951.150391</td>\n",
       "      <td>203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29</th>\n",
       "      <td>21935.199219</td>\n",
       "      <td>22060.550781</td>\n",
       "      <td>21860.650391</td>\n",
       "      <td>21982.800781</td>\n",
       "      <td>21982.800781</td>\n",
       "      <td>360200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1479 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open          High           Low         Close  \\\n",
       "Date                                                                 \n",
       "2018-03-01  10479.950195  10525.500000  10447.150391  10458.349609   \n",
       "2018-03-05  10428.299805  10428.700195  10323.900391  10358.849609   \n",
       "2018-03-06  10420.500000  10441.349609  10215.900391  10249.250000   \n",
       "2018-03-07  10232.950195  10243.349609  10141.549805  10154.200195   \n",
       "2018-03-08  10216.250000  10270.349609  10146.400391  10242.650391   \n",
       "...                  ...           ...           ...           ...   \n",
       "2024-02-23  22290.000000  22297.500000  22186.099609  22212.699219   \n",
       "2024-02-26  22169.199219  22202.150391  22075.150391  22122.050781   \n",
       "2024-02-27  22090.199219  22218.250000  22085.650391  22198.349609   \n",
       "2024-02-28  22214.099609  22229.150391  21915.849609  21951.150391   \n",
       "2024-02-29  21935.199219  22060.550781  21860.650391  21982.800781   \n",
       "\n",
       "               Adj Close  Volume  \n",
       "Date                              \n",
       "2018-03-01  10458.349609  176000  \n",
       "2018-03-05  10358.849609  194000  \n",
       "2018-03-06  10249.250000  222900  \n",
       "2018-03-07  10154.200195  249500  \n",
       "2018-03-08  10242.650391  226400  \n",
       "...                  ...     ...  \n",
       "2024-02-23  22212.699219  226000  \n",
       "2024-02-26  22122.050781  207800  \n",
       "2024-02-27  22198.349609  252200  \n",
       "2024-02-28  21951.150391  203000  \n",
       "2024-02-29  21982.800781  360200  \n",
       "\n",
       "[1479 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nifty50 = yf.download(\"^NSEI\", start, end)\n",
    "nifty50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b390b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting csv for reference\n",
    "#nifty50.to_csv(\"nifty50_file.csv\", index = True)\n",
    "\n",
    "# Importing DataFrame\n",
    "#nifty50 = pd.read_csv('/kaggle/input/nifty50/nifty50_file.csv')\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "#nifty50.set_index('Date', inplace=True)\n",
    "\n",
    "# Printing the DataFrame\n",
    "#print(nifty50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad03e7",
   "metadata": {},
   "source": [
    "# *Creating the Dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35875ba4",
   "metadata": {},
   "source": [
    "**Created the dataset of all above mentioned companies and index together**\n",
    "\n",
    "* HCL Tech\n",
    "* Sunpharma\n",
    "* HDFC Bank\n",
    "* DLF\n",
    "* Nifty50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30d3612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all individual Company details dataset into DataFrames\n",
    "hcltech = pd.DataFrame(hcltech)\n",
    "sunpharma = pd.DataFrame(sunpharma)\n",
    "hdfcbank = pd.DataFrame(hdfcbank)\n",
    "dlf = pd.DataFrame(dlf)\n",
    "nifty50 = pd.DataFrame(nifty50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20fea6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to each DataFrame to store the table names\n",
    "hcltech['Company/Index Name'] = 'HCL Technologies Ltd.'\n",
    "sunpharma['Company/Index Name'] = 'Sun Pharmaceutical Industries Ltd.'\n",
    "hdfcbank['Company/Index Name'] = 'HDFC Bank Ltd.'\n",
    "dlf['Company/Index Name'] = 'DLF Ltd.'\n",
    "nifty50['Company/Index Name'] = 'NIFTY50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18b5b834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Company/Index Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>471.899994</td>\n",
       "      <td>476.225006</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>471.399994</td>\n",
       "      <td>403.986603</td>\n",
       "      <td>2772230</td>\n",
       "      <td>HCL Technologies Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>471.399994</td>\n",
       "      <td>472.325012</td>\n",
       "      <td>458.899994</td>\n",
       "      <td>466.049988</td>\n",
       "      <td>399.401703</td>\n",
       "      <td>3747704</td>\n",
       "      <td>HCL Technologies Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>469.000000</td>\n",
       "      <td>476.500000</td>\n",
       "      <td>463.250000</td>\n",
       "      <td>466.399994</td>\n",
       "      <td>399.701508</td>\n",
       "      <td>2929756</td>\n",
       "      <td>HCL Technologies Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-07</th>\n",
       "      <td>469.000000</td>\n",
       "      <td>476.399994</td>\n",
       "      <td>466.899994</td>\n",
       "      <td>474.774994</td>\n",
       "      <td>406.878906</td>\n",
       "      <td>5695220</td>\n",
       "      <td>HCL Technologies Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-08</th>\n",
       "      <td>476.500000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>472.774994</td>\n",
       "      <td>475.325012</td>\n",
       "      <td>407.350250</td>\n",
       "      <td>4238350</td>\n",
       "      <td>HCL Technologies Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-23</th>\n",
       "      <td>22290.000000</td>\n",
       "      <td>22297.500000</td>\n",
       "      <td>22186.099609</td>\n",
       "      <td>22212.699219</td>\n",
       "      <td>22212.699219</td>\n",
       "      <td>226000</td>\n",
       "      <td>NIFTY50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-26</th>\n",
       "      <td>22169.199219</td>\n",
       "      <td>22202.150391</td>\n",
       "      <td>22075.150391</td>\n",
       "      <td>22122.050781</td>\n",
       "      <td>22122.050781</td>\n",
       "      <td>207800</td>\n",
       "      <td>NIFTY50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-27</th>\n",
       "      <td>22090.199219</td>\n",
       "      <td>22218.250000</td>\n",
       "      <td>22085.650391</td>\n",
       "      <td>22198.349609</td>\n",
       "      <td>22198.349609</td>\n",
       "      <td>252200</td>\n",
       "      <td>NIFTY50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-28</th>\n",
       "      <td>22214.099609</td>\n",
       "      <td>22229.150391</td>\n",
       "      <td>21915.849609</td>\n",
       "      <td>21951.150391</td>\n",
       "      <td>21951.150391</td>\n",
       "      <td>203000</td>\n",
       "      <td>NIFTY50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29</th>\n",
       "      <td>21935.199219</td>\n",
       "      <td>22060.550781</td>\n",
       "      <td>21860.650391</td>\n",
       "      <td>21982.800781</td>\n",
       "      <td>21982.800781</td>\n",
       "      <td>360200</td>\n",
       "      <td>NIFTY50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7407 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open          High           Low         Close  \\\n",
       "Date                                                                 \n",
       "2018-03-01    471.899994    476.225006    469.000000    471.399994   \n",
       "2018-03-05    471.399994    472.325012    458.899994    466.049988   \n",
       "2018-03-06    469.000000    476.500000    463.250000    466.399994   \n",
       "2018-03-07    469.000000    476.399994    466.899994    474.774994   \n",
       "2018-03-08    476.500000    482.000000    472.774994    475.325012   \n",
       "...                  ...           ...           ...           ...   \n",
       "2024-02-23  22290.000000  22297.500000  22186.099609  22212.699219   \n",
       "2024-02-26  22169.199219  22202.150391  22075.150391  22122.050781   \n",
       "2024-02-27  22090.199219  22218.250000  22085.650391  22198.349609   \n",
       "2024-02-28  22214.099609  22229.150391  21915.849609  21951.150391   \n",
       "2024-02-29  21935.199219  22060.550781  21860.650391  21982.800781   \n",
       "\n",
       "               Adj Close   Volume     Company/Index Name  \n",
       "Date                                                      \n",
       "2018-03-01    403.986603  2772230  HCL Technologies Ltd.  \n",
       "2018-03-05    399.401703  3747704  HCL Technologies Ltd.  \n",
       "2018-03-06    399.701508  2929756  HCL Technologies Ltd.  \n",
       "2018-03-07    406.878906  5695220  HCL Technologies Ltd.  \n",
       "2018-03-08    407.350250  4238350  HCL Technologies Ltd.  \n",
       "...                  ...      ...                    ...  \n",
       "2024-02-23  22212.699219   226000                NIFTY50  \n",
       "2024-02-26  22122.050781   207800                NIFTY50  \n",
       "2024-02-27  22198.349609   252200                NIFTY50  \n",
       "2024-02-28  21951.150391   203000                NIFTY50  \n",
       "2024-02-29  21982.800781   360200                NIFTY50  \n",
       "\n",
       "[7407 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating the Datasets\n",
    "df = pd.concat([hcltech, sunpharma, hdfcbank, dlf, nifty50])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3079fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting csv for reference\n",
    "#df.to_csv(\"stock_analysis_df.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78231f",
   "metadata": {},
   "source": [
    "# Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "200d66bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Company/Index Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>471.899994</td>\n",
       "      <td>476.225006</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>471.399994</td>\n",
       "      <td>403.986603</td>\n",
       "      <td>2772230</td>\n",
       "      <td>HCL Technologies Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>471.399994</td>\n",
       "      <td>472.325012</td>\n",
       "      <td>458.899994</td>\n",
       "      <td>466.049988</td>\n",
       "      <td>399.401703</td>\n",
       "      <td>3747704</td>\n",
       "      <td>HCL Technologies Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>469.000000</td>\n",
       "      <td>476.500000</td>\n",
       "      <td>463.250000</td>\n",
       "      <td>466.399994</td>\n",
       "      <td>399.701508</td>\n",
       "      <td>2929756</td>\n",
       "      <td>HCL Technologies Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-07</th>\n",
       "      <td>469.000000</td>\n",
       "      <td>476.399994</td>\n",
       "      <td>466.899994</td>\n",
       "      <td>474.774994</td>\n",
       "      <td>406.878906</td>\n",
       "      <td>5695220</td>\n",
       "      <td>HCL Technologies Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-08</th>\n",
       "      <td>476.500000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>472.774994</td>\n",
       "      <td>475.325012</td>\n",
       "      <td>407.350250</td>\n",
       "      <td>4238350</td>\n",
       "      <td>HCL Technologies Ltd.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2018-03-01  471.899994  476.225006  469.000000  471.399994  403.986603   \n",
       "2018-03-05  471.399994  472.325012  458.899994  466.049988  399.401703   \n",
       "2018-03-06  469.000000  476.500000  463.250000  466.399994  399.701508   \n",
       "2018-03-07  469.000000  476.399994  466.899994  474.774994  406.878906   \n",
       "2018-03-08  476.500000  482.000000  472.774994  475.325012  407.350250   \n",
       "\n",
       "             Volume     Company/Index Name  \n",
       "Date                                        \n",
       "2018-03-01  2772230  HCL Technologies Ltd.  \n",
       "2018-03-05  3747704  HCL Technologies Ltd.  \n",
       "2018-03-06  2929756  HCL Technologies Ltd.  \n",
       "2018-03-07  5695220  HCL Technologies Ltd.  \n",
       "2018-03-08  4238350  HCL Technologies Ltd.  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67c30019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 7407 entries, 2018-03-01 to 2024-02-29\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Open                7407 non-null   float64\n",
      " 1   High                7407 non-null   float64\n",
      " 2   Low                 7407 non-null   float64\n",
      " 3   Close               7407 non-null   float64\n",
      " 4   Adj Close           7407 non-null   float64\n",
      " 5   Volume              7407 non-null   int64  \n",
      " 6   Company/Index Name  7407 non-null   object \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 462.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Fetching the structure of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Descriptive Analysis\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3ceb0",
   "metadata": {},
   "source": [
    "**From the descriptive analysis, its inferred that the data is not normally distributed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d16f8",
   "metadata": {},
   "source": [
    "# *Data Cleaning & Pre-processing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96976da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Value Treatment\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab546d96",
   "metadata": {},
   "source": [
    "## Inference:\n",
    "**In this data, we are considering only the working days of the Stock Market hence the data doesn't include Holidays.**\n",
    "\n",
    "**Missing values not found for any other column**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dec035",
   "metadata": {},
   "source": [
    "## *Normalising the data*\n",
    "\n",
    "Usually, we do outlier treatment first and then normalization. But in case of Stock Market data etc, normalization is done before outlier treatment for the following reasons:\n",
    "\n",
    "* to preserve the data relationship - In stock market data, the relative movements and relationships between different stock prices and financial indicators are often more important than the absolute values.\n",
    "* applying outlier treatment on normalized data ensures that each feature is treated equally and consistently. Outliers can have a disproportionate impact on unscaled data, potentially leading to biased outlier detection and treatment. This becomes relevant if we are doing Principal Component Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b336d43",
   "metadata": {},
   "source": [
    "**Creating function \"normalize_dataset(df)\" is designed to normalize the numerical columns of a given DataFrame using the Min-Max scaling technique**\n",
    "\n",
    "**Breakdown:**\n",
    "1. Input Parameter:\n",
    "df: This is the DataFrame that you want to normalize.\n",
    "2. Selecting Numerical Columns:\n",
    "The function first identifies the numerical columns within the DataFrame. It does this by using the select_dtypes method with the argument include=[float, int]. This filters and selects only the columns with data types of float and int, which are typically the data types for numerical values.\n",
    "3. Normalization with Min-Max Scaler:\n",
    "It then initializes a Min-Max scaler object using scaler = MinMaxScaler(). The Min-Max scaler is a method used to transform numerical data into a specific range, often between 0 and 1.\n",
    "Next, it applies the Min-Max scaling transformation to the selected numerical columns using df[numerical_columns] = scaler.fit_transform(df[numerical_columns]). This step scales each numerical column independently, so that the minimum value in each column becomes 0, the maximum becomes 1, and all other values are scaled proportionally within this range.\n",
    "4. Return the Normalized Dataset:\n",
    "Finally, the function returns the original DataFrame df, but with the numerical columns normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258dc86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(data):\n",
    "    \"\"\"\n",
    "Normalize the numerical columns of a given DataFrame using the Min-Max scaling technique.\n",
    "\n",
    "Parameters:\n",
    "----------\n",
    "data : pandas.DataFrame\n",
    "    The DataFrame containing the data to be normalized.\n",
    "\n",
    "Returns:\n",
    "-------\n",
    "pandas.DataFrame\n",
    "    A new DataFrame with the same structure as the input 'data', but with the\n",
    "    numerical columns scaled to the range [0, 1] using Min-Max scaling.\n",
    "\n",
    "Usage:\n",
    "------\n",
    "# Example usage:\n",
    "    normalized_data = normalize_dataset(df)\n",
    "    \"\"\"\n",
    "    # Create a new DataFrame to store normalized values\n",
    "    normalized_data = data.copy()\n",
    "    \n",
    "    # Select only numerical columns\n",
    "    numerical_columns = normalized_data.select_dtypes(include=[float, int]).columns\n",
    "    \n",
    "    # Normalize numerical columns using Min-Max scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data[numerical_columns] = scaler.fit_transform(normalized_data[numerical_columns])\n",
    "    \n",
    "    # Return the normalized dataset\n",
    "    return normalized_data\n",
    "\n",
    "# Calling the Function\n",
    "normalized_data = normalize_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeebdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed080d9b",
   "metadata": {},
   "source": [
    "**In summary, this function takes a DataFrame, identifies the numerical columns, scales the values within those columns to a specified range (typically 0 to 1), and returns the DataFrame with the normalized numerical values. This is useful for ensuring that numerical features are on a similar scale, which can be important for certain machine learning algorithms and data analysis techniques.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88c07d4",
   "metadata": {},
   "source": [
    "## *Outlier Treatment*             \n",
    "\n",
    "\n",
    "**This function named mark_outliers_zscore is intended for identifying outliers in a dataset based on the z-score method.** \n",
    "\n",
    "**Breakdown:**\n",
    "1. Input Parameters:\n",
    "* data: This parameter represents the dataset or DataFrame in which you want to identify outliers.\n",
    "* column_name: It specifies the name of the column within the dataset where you want to detect outliers.\n",
    "* threshold: This is an optional parameter with a default value of 3.0. It determines the threshold beyond which data points are considered outliers based on their z-scores.\n",
    "2. Calculating Z-Scores:\n",
    "The function calculates the z-scores for the specified column. Z-scores measure how many standard deviations a data point is away from the mean of the column. The formula used is: (x - mean) / standard deviation, where x is each data point in the specified column.\n",
    "3. Creating an 'Outlier' Column:\n",
    "It creates a new column named 'Outlier' in the input dataset data.\n",
    "4. Identifying Outliers:\n",
    "For each data point in the specified column, it compares the absolute value of its z-score to the provided threshold. If the absolute z-score is greater than the threshold, it is considered an outlier. Otherwise, it's not considered an outlier.\n",
    "5. Printing Unique Outlier Values:\n",
    "The function then prints the unique values found in the 'Outlier' column. This will typically show True for data points that are outliers according to the specified threshold and False for non-outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256a3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to identify Outliers\n",
    "def mark_outliers_zscore(data, column_name, threshold=3.0):\n",
    "    \"\"\"\n",
    "Detects and treats outliers in data using z score.\n",
    "\n",
    "Parameters:\n",
    "-----------\n",
    "    data: A list or NumPy array of data.\n",
    "    cutoff: The cutoff value for z scores. Any data point with a z score greater than\n",
    "    cutoff or less than -cutoff is considered an outlier.\n",
    "    \n",
    "Returns:\n",
    "--------\n",
    "    A list or NumPy array of the data with outliers removed.\n",
    "    \n",
    "Usage:\n",
    "------\n",
    "    df_open = mark_outliers_zscore(normalized_data, 'Open')\n",
    "    \"\"\"\n",
    "    # Create a new DataFrame to store normalized values\n",
    "    outlier_data = data.copy()\n",
    "    \n",
    "    # Calculate the z-scores for the specified column\n",
    "    z_scores = (outlier_data[column_name] - outlier_data[column_name].mean()) / outlier_data[column_name].std()\n",
    "\n",
    "    # Create a new 'Outlier' column based on the z-scores\n",
    "    outlier_data['Outlier'] = abs(z_scores) > threshold\n",
    "\n",
    "    # Return the outlier dataset\n",
    "    return outlier_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba08d0b",
   "metadata": {},
   "source": [
    "**In summary, this function calculates z-scores for a given column in the dataset and marks data points as outliers if their z-scores exceed a certain threshold. The result is a new column in the dataset ('Outlier') that indicates whether each data point in the specified column is an outlier or not, and it prints the unique values in this 'Outlier' column, which will typically be True or False.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to mark outliers using z-score for the 'Open' column\n",
    "stock_analysis_df_open = mark_outliers_zscore(normalized_data, 'Open')\n",
    "stock_analysis_df_open['Outlier'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to mark outliers using z-score for the 'High' column\n",
    "stock_analysis_df_high = mark_outliers_zscore(normalized_data, 'High')\n",
    "stock_analysis_df_high['Outlier'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf117f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to mark outliers using z-score for the 'Low' column\n",
    "stock_analysis_df_low = mark_outliers_zscore(normalized_data, 'Low')\n",
    "stock_analysis_df_low['Outlier'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2896bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to mark outliers using z-score for the 'Close' column\n",
    "stock_analysis_df_close = mark_outliers_zscore(normalized_data, 'Close')\n",
    "stock_analysis_df_close['Outlier'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2974b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to mark outliers using z-score for the 'Adj Close' column\n",
    "stock_analysis_df_adjclose = mark_outliers_zscore(normalized_data, 'Adj Close')\n",
    "stock_analysis_df_adjclose['Outlier'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8307fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to mark outliers using z-score for the 'Volume' column\n",
    "stock_analysis_df_volume = mark_outliers_zscore(normalized_data, 'Volume')\n",
    "stock_analysis_df_volume['Outlier'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc6215e",
   "metadata": {},
   "source": [
    "**The output indicates that there are outliers present in the 'Volume' column**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e918fd6",
   "metadata": {},
   "source": [
    "**Fetching the records with 'Outlier' = 'True'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print rows where the 'Outlier' column is True\n",
    "outliers_true = stock_analysis_df_volume[stock_analysis_df_volume['Outlier'] == True]\n",
    "outliers_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a62f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the company names with outliers present\n",
    "\n",
    "outliers_true['Company/Index Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a7d3b",
   "metadata": {},
   "source": [
    "### Inference:\n",
    "**As the data points in this dataset are actual values of stocks fetched from yfinance, we will not be treating the outlier values occuring in the 'Volume' column.**\n",
    "\n",
    "**Would outlier treatment be of any significance in case of stock market data?**\n",
    "\n",
    "* Outlier identification and treatment can be of significant importance when working with stock market data, but the approach to handling outliers in this context can be complex.\n",
    "* Outliers in stock market data might represent errors, glitches, or data inaccuracies.It could be indicative of significant events, such as earnings releases, news announcements, market crashes, or other market-moving events. Identifying and understanding these outliers can provide valuable insights into market dynamics and investor behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3975b43",
   "metadata": {},
   "source": [
    "# 1. *What was the change in price of the stock overtime?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680e18e",
   "metadata": {},
   "source": [
    "## *Adjusted Closing Price*\n",
    "\n",
    "\n",
    "The Adjusted Closing Price amends a stock's closing price to reflect that stock's value after accounting for any corporate actions. It is often used when examining historical returns or doing a detailed analysis of past performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225f4339",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_list = ['hcltech', 'sunpharma', 'hdfcbank', 'dlf', 'nifty50']\n",
    "company_list = [hcltech, sunpharma, hdfcbank, dlf, nifty50]\n",
    "company_name = ['hcltech', 'sunpharma', 'hdfcbank', 'dlf', 'nifty50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a23cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see a historical view of the adjusted closing price\n",
    "\n",
    "plt.figure(figsize=(15, 25))\n",
    "plt.subplots_adjust(top=1.25, bottom=1.2)\n",
    "\n",
    "for i, company in enumerate(company_list, 1):\n",
    "    plt.subplot(5, 1, i)\n",
    "    company['Adj Close'].plot()\n",
    "    plt.ylabel('Adj Close')\n",
    "    plt.xlabel(None)\n",
    "    plt.title(f\"Adjusted Closing Price of {tech_list[i - 1]}\")\n",
    "\n",
    "plt.savefig('Addj closing price.png')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fae7a8",
   "metadata": {},
   "source": [
    "**Observation : Adjusted closing price of all companies has shown downward trend during the time of COVID-19 Pandemic.**\n",
    "\n",
    "**- HCL TECH : There was normal upside movement uptill 2020 but after COVID downfall share price got doubled within a year having 800 as multiple resistance and support level.**\n",
    "\n",
    "**- Sunpharma : Due to FDA license disapproval stock price was down by 35% in the last quarter of 2018, it did not perform well after that as well and slumped down more in the beginning of COVID, but due to boom in Pharmaceutical industry during pandemic, the share recovered its ATH price in 2021 beginning and has grown continously afer that.**\n",
    "\n",
    "**- HDFC Bank : Share was performing very well before COVID, during pandemic it went down to 750 but recovered fast within 6 months and touched level of 1500 within a year and is prevailing in 1500-1600 since then.**\n",
    "\n",
    "**- DLF : It was showing a sign of good growth before COVID but pandemic proved to be a bane in its story. It took almost a year for the stock to recover but after that it has shown an exponential growth.**\n",
    "\n",
    "**- NIFTY 50 : Index being a result a top 50 companies was growing continously but COVID hit hard and resulted in a fall of 40%, this shows average decline in values of top performing companies but the recovery was quick and it has reached to ATH levels growing continously.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e650c",
   "metadata": {},
   "source": [
    "### *Calculating the Year-on-Year change in the Adjusted Closing Price of each Company/Index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# List of years\n",
    "years = [2018,2019,2020, 2021, 2022, 2023]\n",
    "\n",
    "# Check the day of the week for March 31st in each year\n",
    "for year in years:\n",
    "    date = datetime.date(year, 3, 31)\n",
    "    day_of_week = date.strftime('%A')  # Get the full day name\n",
    "    print(f\"March 31, {year} falls on a {day_of_week}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634c3b9",
   "metadata": {},
   "source": [
    "### ***Fetching data (including year 2018 closing) for year-on-year calculation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79610412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start18 = datetime.strptime('28/03/2018', '%d/%m/%Y')\n",
    "# Display the value of 'start'\n",
    "print(start18)\n",
    "\n",
    "end18 = datetime.strptime('01/04/2023', '%d/%m/%Y')\n",
    "# Display the value of 'start'\n",
    "print(end18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27019b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcltech_2018 = yf.download(\"HCLTECH.NS\", start18, end18)\n",
    "hcltech_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunpharma_2018 = yf.download(\"SUNPHARMA.NS\", start18, end18)\n",
    "sunpharma_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d79bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfcbank_2018 = yf.download(\"HDFCBANK.NS\", start18, end18)\n",
    "hdfcbank_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlf_2018 = yf.download(\"DLF.NS\", start18, end18)\n",
    "dlf_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee44af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty50_2018 = yf.download(\"^NSEI\", start18, end18)\n",
    "nifty50_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d08058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to each DataFrame to store the table names\n",
    "hcltech_2018['Company/Index Name'] = 'HCL Technologies Ltd.'\n",
    "sunpharma_2018['Company/Index Name'] = 'Sun Pharmaceutical Industries Ltd.'\n",
    "hdfcbank_2018['Company/Index Name'] = 'HDFC Bank Ltd.'\n",
    "dlf_2018['Company/Index Name'] = 'DLF Ltd.'\n",
    "nifty50_2018['Company/Index Name'] = 'NIFTY50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34048e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and create a new column for dates\n",
    "hcltech_reset = hcltech_2018.reset_index()\n",
    "#hcltech_reset['DateColumn'] = hcltech_reset['Date']\n",
    "\n",
    "sunpharma_reset = sunpharma_2018.reset_index()\n",
    "#sunpharma_reset['DateColumn'] = sunpharma_reset['Date']\n",
    "\n",
    "hdfcbank_reset = hdfcbank_2018.reset_index()\n",
    "#hdfcbank_reset['DateColumn'] = hdfcbank_reset['Date']\n",
    "\n",
    "dlf_reset = dlf_2018.reset_index()\n",
    "#dlf_reset['DateColumn'] = dlf_reset['Date']\n",
    "\n",
    "nifty50_reset = nifty50_2018.reset_index()\n",
    "#nifty50_reset['DateColumn'] = nifty50_reset['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a034fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all individual company datasets into one DataFrame\n",
    "df_yoy = pd.concat([hcltech_reset, sunpharma_reset, hdfcbank_reset, dlf_reset, nifty50_reset])\n",
    "df_yoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3982a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year end dates (based on the last working days)\n",
    "dates_to_filter = [\"2018-03-28\", \"2019-03-28\", \"2020-03-31\", \"2021-03-31\", \"2022-03-31\", \"2023-03-31\"]\n",
    "\n",
    "# Fetching the records for the year end dates\n",
    "f_rows = df_yoy[df_yoy['Date'].isin(dates_to_filter)]\n",
    "f_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing column names\n",
    "date_yoy = f_rows['Date']\n",
    "company_yoy = f_rows['Company/Index Name']\n",
    "adjclose_yoy = f_rows['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dbb776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe with only relevant columns for ease of analysis\n",
    "pd_yoy = pd.DataFrame({'Date': date_yoy, 'Company': company_yoy,'Adj Close': adjclose_yoy})\n",
    "pd_yoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af788dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the 'Date' column and create a new 'Year' column\n",
    "pd_yoy['Date'] = pd.to_datetime(pd_yoy['Date'])\n",
    "pd_yoy['Year'] = pd_yoy['Date'].dt.year\n",
    "\n",
    "# Sort the DataFrame by 'Company', 'Year', and 'Date'\n",
    "pd_yoy.sort_values(by=['Year', 'Date'], inplace=True) #'Company', \n",
    "\n",
    "# Calculate the year-on-year change for the 'Adj Close' column\n",
    "pd_yoy['Yearly Change'] = (pd_yoy.groupby('Company')['Adj Close'].pct_change() * 100).round(2)\n",
    "\n",
    "# Sort the DataFrame by 'Company' and 'Date'\n",
    "pd_yoy.sort_values(by=['Company', 'Date'], inplace=True)\n",
    "\n",
    "# Create a pivot table\n",
    "pivot_table = pd_yoy.pivot(index='Company', columns='Year', values='Yearly Change')\n",
    "formatted_yoy_df = pivot_table.applymap(lambda x: f'{x:.2f}%')\n",
    "formatted_yoy_df = formatted_yoy_df.drop(columns = 2018)\n",
    "\n",
    "formatted_yoy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fec57c",
   "metadata": {},
   "source": [
    "**Inference:**\n",
    "\n",
    "**During the period 2019 to 2020 (2019-2020):**\n",
    "DLF Ltd, Sun Pharmaceutical Industries Ltd, HCL Technologies Ltd. and HDFC Bank\n",
    "Ltd. experienced significant decreases in their adjusted closing prices\n",
    "\n",
    "The NIFTY50 index, which represents the broader market, had a negative return of -\n",
    "25.69% during this period, indicating a general market downturn.\n",
    "\n",
    "\n",
    "**During the period 2020 to 2021 (2020-2021):**\n",
    "In 2021, there was a significant recovery in stock prices.\n",
    "DLF Ltd, Sun Pharmaceutical Industries Ltd, HCL Technologies Ltd. and HDFC Bank\n",
    "showed strong positive returns\n",
    "\n",
    "The NIFTY50 index rebounded with a positive return of 70.87%, reflecting a broader\n",
    "market recovery.\n",
    "\n",
    "\n",
    "**During the period 2021 to 2022 (2021-2022):**\n",
    "Most of the stocks continued to perform well in 2022.\n",
    "\n",
    "* DLF Ltd. and Sun Pharmaceutical Industries Ltd. showed positive returns of 33.40% and 54.63%, respectively.\n",
    "* HCL Technologies Ltd. and HDFC Bank Ltd. also had positive returns, although more modest, with HCL Technologies Ltd. gaining 22.45% and HDFC Bank Ltd. gaining 1.13%.\n",
    "* The NIFTY50 index had a positive return of 18.88%, indicating overall market growth.\n",
    "\n",
    "\n",
    "**During the period 2022 to 2023 (2022-2023):**\n",
    "In 2023, most stocks experienced a mixed performance. \n",
    "* DLF Ltd. had a negative return of -5.50%, indicating a decline in its adjusted closing price.\n",
    "* HCL Technologies Ltd. and HDFC Bank Ltd. also saw minor negative returns\n",
    "* Sun Pharmaceutical Industries Ltd. continued to perform well with a positive\n",
    "* return of 8.63%.\n",
    "* The NIFTY50 index had a slight decline with a negative return of -0.60%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf37a6",
   "metadata": {},
   "source": [
    "# *2. What was the weekly return of the stock on average?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44aa2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index to a DatetimeIndex\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9690dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index to a DatetimeIndex\n",
    "hcltech.index = pd.to_datetime(hcltech.index)\n",
    "\n",
    "# Convert the index to a DatetimeIndex\n",
    "sunpharma.index = pd.to_datetime(sunpharma.index)\n",
    "\n",
    "# Convert the index to a DatetimeIndex\n",
    "hdfcbank.index = pd.to_datetime(hdfcbank.index)\n",
    "\n",
    "# Convert the index to a DatetimeIndex\n",
    "dlf.index = pd.to_datetime(dlf.index)\n",
    "\n",
    "# Convert the index to a DatetimeIndex\n",
    "nifty50.index = pd.to_datetime(nifty50.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90e37c",
   "metadata": {},
   "source": [
    "### *Filtering data for every Thursday (stock market end of week)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b32eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thurs = df[df.index.weekday == 3]\n",
    "df_thurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fdef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcltech_thurs = hcltech[hcltech.index.weekday == 3]\n",
    "hcltech_thurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101bdbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunpharma_thurs = sunpharma[sunpharma.index.weekday == 3]\n",
    "sunpharma_thurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfcbank_thurs = hdfcbank[hdfcbank.index.weekday == 3]\n",
    "hdfcbank_thurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc50fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlf_thurs = dlf[dlf.index.weekday == 3]\n",
    "dlf_thurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19cc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty50_thurs = nifty50[nifty50.index.weekday == 3]\n",
    "nifty50_thurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044b750d",
   "metadata": {},
   "source": [
    "**The below code is intended to calculate the weekly returns for each company in a list of DataFrames called company_list_week.** **Breakdown:**\n",
    "1. Loop Over company_list_week:\n",
    "The code starts a loop that iterates over each DataFrame in the company_list_week. Each DataFrame presumably contains financial data for a specific company.\n",
    "2. Calculating Weekly Returns:\n",
    "* within the loop, for each company, it calculates the weekly returns and stores them in a new column named 'Weekly Return' within that company's DataFrame.\n",
    "* company['Adj Close'] accesses the 'Adj Close' column of the DataFrame. This column is typically used to represent the adjusted closing price of a company's stock.\n",
    "* .pct_change() is a pandas function that calculates the percentage change between each element and the previous element in a Series (or DataFrame column). This operation effectively computes the weekly returns as the percentage change in the 'Adj Close' prices.\n",
    "\n",
    "**So, after this loop completes, each DataFrame in company_list_week will have a new column named 'Weekly Return', which contains the weekly returns calculated as the percentage change in the 'Adj Close' prices. These returns represent the weekly investment performance of each company's stock.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462648e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list_week = [hcltech_thurs,sunpharma_thurs,hdfcbank_thurs,dlf_thurs,nifty50_thurs]\n",
    "\n",
    "# We'll use pct_change to find the percent change for each week\n",
    "for company in company_list_week:\n",
    "    company['Weekly Return'] = company['Adj Close'].pct_change()\n",
    "\n",
    "# Then we'll plot the daily return percentage\n",
    "fig, axes = plt.subplots(nrows=5, ncols=1)\n",
    "fig.set_figheight(25)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "hcltech_thurs['Weekly Return'].plot(ax=axes[0], legend=True, linestyle='--', marker='o')\n",
    "axes[0].set_title('hcltech')\n",
    "\n",
    "sunpharma_thurs['Weekly Return'].plot(ax=axes[1], legend=True, linestyle='--', marker='o')\n",
    "axes[1].set_title('sunpharma')\n",
    "\n",
    "hdfcbank_thurs['Weekly Return'].plot(ax=axes[2], legend=True, linestyle='--', marker='o')\n",
    "axes[2].set_title('hdfcbank')\n",
    "\n",
    "dlf_thurs['Weekly Return'].plot(ax=axes[3], legend=True, linestyle='--', marker='o')\n",
    "axes[3].set_title('dlf')\n",
    "\n",
    "nifty50_thurs['Weekly Return'].plot(ax=axes[4], legend=True, linestyle='--', marker='o')\n",
    "axes[4].set_title('nifty50')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743167d",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "**These charts show us the distribution of weekly returns of these stocks:**\n",
    "\n",
    "1. HCLTECH: The weekly data is mostly scattered in the range of -5% to 5%. Being a less volatile share, HCLTECH doesn't have any major weekly.\n",
    "2. Sunpharma: This share is more volatile than HCLTECH as the data is mostly scattered in the range of -10% to 10% except for the Pandemic period. Being a Pharmaceutical company, it has shown good returns in the COVID-19 period.\n",
    "3. HDFCBank: The weekly data is mostly scattered in the range of -5% to 5%. In 2019, the company declared a 30% growth in Y-O-Y Net Profit for F.Y. 2018, which lead to the sudden spike. Similarly, in the year 2021, the company reported 18% growth in Y-O-Y Net Profit for Q4 2020.\n",
    "4. DLF: This share is more volatile as the data is mostly scattered in the range of -15% to 15%.\n",
    "5. NIFTY50: Being an index of 50 different shares the return of NIFTY is balanced, making it less volatile.\n",
    "\n",
    "**All the above have shown diversions from their behaviour During the COVID-19 Pandemic and Post Pandemic Market Recovery Time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non-finite values in the data\n",
    "\n",
    "non_finite_mask = ~np.isfinite(company['Weekly Return'])\n",
    "if non_finite_mask.any():\n",
    "    print(f\"Non-finite values found: {company['Weekly Return'][non_finite_mask]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b387fd0f",
   "metadata": {},
   "source": [
    "One recorded dated 01/04/2018 has a Non-Finite value. Replacing the same with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762bb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace non-finite values with the mean\n",
    "\n",
    "mean_return = np.nanmean(company['Weekly Return'])\n",
    "company.loc[non_finite_mask, 'Weekly Return'] = mean_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79289c",
   "metadata": {},
   "source": [
    "### Now, let's get an overall look at the weekly return using a histogram. \n",
    "\n",
    "**We'll use seaborn to create both a histogram and kde plot on the same figure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff5f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 25))\n",
    "\n",
    "for i, company in enumerate(company_list_week, 1):\n",
    "    plt.subplot(5, 1, i)\n",
    "    company['Weekly Return'].hist(bins=50)\n",
    "    plt.xlabel('Weekly Return')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'{company_name[i - 1]}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('Weekly return.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab694d",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "**The Frequency so plotted for the above data, tend more to the positive side rather than the negative and the outliers seen are mostly due to the COVID-19 Pandemic.**\n",
    "\n",
    "**Reasons for other outliers, if any, have been stated in the above observations for scatter plot.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e16aa56",
   "metadata": {},
   "source": [
    "# *3. What was the moving average of the various stocks?*\n",
    "\n",
    "The moving average (MA) is a simple technical analysis tool that smooths out price data by creating a constantly updated average price. The average is taken over a specific period of time, like 10 days, 20 minutes, 30 weeks, or any time period the trader chooses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce32c4",
   "metadata": {},
   "source": [
    "**This code utilizes nested loops and the Pandas library to calculate moving averages (MAs) for a list of specified moving average days (ma_days) for a list of companies (company_list).**\n",
    "\n",
    "**Breakdown:**\n",
    "\n",
    "1. Outer Loop (for ma in ma_days):\n",
    "This loop iterates over a list of moving average day values (ma_days), where each value represents the number of days to use for calculating the moving average.\n",
    "2. Inner Loop (for company in company_list):\n",
    "Inside the outer loop, there is an inner loop that iterates over a list of company dataframes (company_list). Each dataframe represents data for a specific company.\n",
    "3. Creating Column Names:\n",
    "Within the inner loop, a string variable column_name is created using f-strings. This string represents the name of the column that will store the moving average for the current company and the current moving average period (specified by ma).\n",
    "4. Calculating Moving Averages:\n",
    "The code then calculates the moving average for the 'Adj Close' column of the current company's dataframe using the rolling() method with a window size of ma days. This rolling mean is calculated for each row in the dataframe.\n",
    "5. Assigning the Moving Averages to Columns:\n",
    "The calculated moving average values are assigned to a new column in the current company's dataframe. This new column is named based on the column_name created earlier, which includes the specific moving average period.\n",
    "**So, for each company in the company_list, this code calculates and assigns moving averages for each of the specified ma_days, resulting in additional columns in each company's dataframe that contain the moving average values for different time periods.**\n",
    "\n",
    "**Also, the results fetched are being displayed in the form of graph for each company/index separately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_days = [50, 120, 200]\n",
    "\n",
    "for ma in ma_days:\n",
    "    for company in company_list:\n",
    "        column_name = f\"MA for {ma} days\"\n",
    "        company[column_name] = company['Adj Close'].rolling(ma).mean()\n",
    "        \n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=1)\n",
    "fig.set_figheight(25)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "hcltech[['Adj Close', 'MA for 50 days', 'MA for 120 days', 'MA for 200 days']].plot(ax=axes[0])\n",
    "axes[0].set_title('hcltech')\n",
    "\n",
    "sunpharma[['Adj Close', 'MA for 50 days', 'MA for 120 days', 'MA for 200 days']].plot(ax=axes[1])\n",
    "axes[1].set_title('sunpharma')\n",
    "\n",
    "hdfcbank[['Adj Close', 'MA for 50 days', 'MA for 120 days', 'MA for 200 days']].plot(ax=axes[2])\n",
    "axes[2].set_title('hdfcbank')\n",
    "\n",
    "dlf[['Adj Close', 'MA for 50 days', 'MA for 120 days', 'MA for 200 days']].plot(ax=axes[3])\n",
    "axes[3].set_title('dlf')\n",
    "\n",
    "nifty50[['Adj Close', 'MA for 50 days', 'MA for 120 days', 'MA for 200 days']].plot(ax=axes[4])\n",
    "axes[4].set_title('nifty50')\n",
    "\n",
    "plt.savefig('moving average of the various stocks.png')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55feafd5",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "Moving averages are used to smooth out the price data and identify trends. They can also be used to identify support and resistance levels.\n",
    "\n",
    "Support is a price level where the price is likely to find buyers. Resistance is a price level where the price is likely to find sellers.\n",
    "\n",
    "**50-day moving average (50DMA):**\n",
    "The 50-day moving average (50DMA) is calculated by taking the average of a stock's closing prices over the past 50 trading days. It provides a short- to medium-term view of price trends. Traders and investors use the 50DMA to identify short- to medium-term trends and potential support and resistance levels. When the stock price is above the 50DMA, it suggests that the stock is in an uptrend. Conversely, when the price is below the 50DMA, it suggests a downtrend\n",
    "\n",
    "**120-day moving average (120DMA):**\n",
    "The 120-day moving average (120DMA) is calculated using the average of closing prices over the past 120 trading days. It provides a longer-term view compared to the 50DMA. The 120DMA is often used by medium- to long-term investors to identify longer-term trends and to help filter out short-term price fluctuations. Similar to the 50DMA, the relationship between the stock price and the 120DMA can indicate trend direction and potential support and resistance levels.\n",
    "\n",
    "**200-day moving average (200DMA):**\n",
    "The 200-day moving average (200DMA) is one of the most widely followed moving averages. It calculates the average closing price over the past 200 trading days. The 200DMA provides a long-term perspective and is often used to gauge the overall health of a stock or market index. When the stock price is above the 200DMA, it generally suggests a bullish trend, and when it's below, it indicates a bearish trend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cab882",
   "metadata": {},
   "source": [
    "**Inference:**\n",
    "* HCLTech has been the strongest performer, followed by HDFC Bank.\n",
    "* HCLTech and HDFC Bank are both trading below their 50-day and 120-day moving averages, which suggests that they may be due for a pullback.\n",
    "* Sun Pharma is trading above its 200-day moving average, but below its 50-day & 120-day moving average.\n",
    "* Nifty 50 is trading below its 50-day, 120-day, and 200-day moving averages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a9f5b",
   "metadata": {},
   "source": [
    "# 4. What was the correlation between different stocks closing prices?\n",
    "\n",
    "\n",
    "Correlation is a statistic that measures the degree to which two variables move in relation to each other which has a value that must fall between -1.0 and +1.0. Correlation measures association, but doesn’t show if x causes y or vice versa — or if the association is caused by a third factor.\n",
    "\n",
    "**Now, we want to analyze the returns of all the stocks in our listwith all the ['Adj Close'] columns for each of the stocks dataframes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0779bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6099f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage change in 'Adj Close' for each 'Company/Index Name'\n",
    "df['Percent Change'] = df.groupby('Company/Index Name')['Adj Close'].pct_change()\n",
    "\n",
    "# Pivot the DataFrame to show the result in separate columns for each 'Company/Index Name'\n",
    "result_df = df.pivot(columns='Company/Index Name', values='Percent Change')\n",
    "\n",
    "# Display the first few rows of the result DataFrame\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792a805",
   "metadata": {},
   "source": [
    "**Now, we can compare the weekly percentage return of two stocks to check how correlated. First let's see a stock compared to itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing \"NIFTY50\" to itself should show a perfectly linear relationship\n",
    "sns.jointplot(x='NIFTY50', y='NIFTY50', data=result_df, kind='scatter', color='seagreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78989add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use joinplot to compare the daily returns of \"HCL Technologies Ltd.\" and \"NIFTY50\"\n",
    "sns.jointplot(x='HCL Technologies Ltd.', y='NIFTY50', data=result_df, kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52fdbf9",
   "metadata": {},
   "source": [
    "**So now, we can see that if two stocks are perfectly (and positivley) correlated with each other a linear relationship bewteen its weekly return values should occur.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c5fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling pairplot on our DataFrame for an automatic visual analysis of all the comparisons\n",
    "sns.pairplot(result_df, kind='reg')\n",
    "\n",
    "# Set the font size for X and Y-axis titles\n",
    "plt.rcParams['axes.labelsize'] = 8 \n",
    "\n",
    "plt.savefig('pairplot between companies.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa6b27",
   "metadata": {},
   "source": [
    "### **Observations:**\n",
    "Above we can see all the relationships on daily returns between all the stocks. A quick glance shows an interesting correlation between NIFTY50 and HDFC Bank Ltd. weekly returns. This relation exists because HDFC Bank Ltd. is one of the major contributors in NIFTY50 Index.\n",
    "\n",
    "**It might be interesting to investigate that individual comparison.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c2e7e7",
   "metadata": {},
   "source": [
    "### To get actual numerical values for the correlation between the stocks' weekly return values, we do a correlation plot. By comparing the Adjusted closing prices, we can see interesting relationship between different stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feecfec",
   "metadata": {},
   "source": [
    "### Plotting the above Numerical Values in a HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d3402",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.heatmap(result_df.corr(), annot=True, cmap='Blues')\n",
    "plt.title('Correlation of stock Weekly return')\n",
    "\n",
    "    \n",
    "plt.savefig('correlation between companies.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e30b1",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "**Investors use the correlation of stocks to measure the risk of their portfolio and to diversify their investments.**\n",
    "\n",
    "In other words, investors want to know how much the price of one stock will move in relation to the price of another stock. If the two stocks are highly correlated, then they will move in the same direction, which means that the investor's portfolio will be more risky. However, if the two stocks are not correlated, then they will move in different directions, which can help to reduce the risk of the portfolio.\n",
    "\n",
    "* **DLF Ltd : It is less aligned with movement in Sun Pharma and HCL but it is moving in direction with NIFTY 50.**\n",
    "\n",
    "* **HCL TECH: It is not majorly effected with change in any of the stocks selected apart from NIFTY 50.**\n",
    "\n",
    "* **HDFC BANK: HDFC Bank have major impact on movement of NIFTY 50 as it has more weightage in Index than any other stock.**\n",
    "\n",
    "* **NIFTY50: It gets influenced by the weightage of individual shares, with HDFC Bank and DLF exhibiting stronger correlations.**\n",
    "\n",
    "* **Sun Pharma: It is not much correlated with any of another stock as it does show major unidirectional change with other shares, HDFC and HCL have adverse effect on this stock price most of the time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15687bbb",
   "metadata": {},
   "source": [
    "# 5. *How much value do we put at risk by investing in a particular stock?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb21413",
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = result_df.dropna() # result_df is the dataframe of daily percentange change of 'Adj Close' of all stocks\n",
    "\n",
    "area = np.pi * 20\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(rets.mean(), rets.std(), s=area)\n",
    "plt.xlabel('Expected return')\n",
    "plt.ylabel('Risk')\n",
    "\n",
    "for label, x, y in zip(rets.columns, rets.mean(), rets.std()):\n",
    "    plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom', \n",
    "                 arrowprops=dict(arrowstyle='->', color='red', connectionstyle='arc3,rad=0.3'))\n",
    "    \n",
    "plt.savefig('Risk By investing in a particular stock.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c2c05c",
   "metadata": {},
   "source": [
    "### Inference:\n",
    "**It is usually said that \"Lower the risk, Lower the return and Higher the risk, Higher the return\", but from the above graph we can see that HCL Technologies Ltd. is defying the quote and with medium risk is providing the highest return**\n",
    "\n",
    "**DLF here is most riskiest stock as it has a daily risk of 2.8% movement in stock, it indicates that the stock is more volatile even in long term, but it is also having good returns.**\n",
    "\n",
    "**On the other hand, SunPharma and HDFC have less risk and safer returns as compared to HCL and DLF. These are more beneficial for risk averting investors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48491b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a917402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00bf74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow3.9.5]",
   "language": "python",
   "name": "conda-env-tensorflow3.9.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
